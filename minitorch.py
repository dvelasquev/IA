# -*- coding: utf-8 -*-
"""MiniTorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/jdmartinev/ArtificialIntelligenceIM/blob/main/Lecture04/notebooks/MiniTorch.ipynb
"""

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
np.random.seed(0)
from tqdm import tqdm
from matplotlib import gridspec
from sklearn.datasets import make_classification
import random
import math
import torch.nn.functional as F

# Define a transform to normalize the data
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
# Download and load the training data
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)
# Download and load the test data
testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)

# Example: Iterate over a few batches
for images, labels in trainloader:
    print(images.shape, labels.shape)
    break

# Check some examples
for images, labels in trainloader:
    # Denormalize the images for plotting
    images = images * 0.5 + 0.5
    plt.figure(figsize=(10, 10))
    for i in range(9):  # Plot 9 images
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i][0], cmap='gray')  # images[i][0] for grayscale images
        plt.title(f"Label: {labels[i].item()}")
        plt.axis('off')
    plt.show()
    break

class Net:
    """
    A sequential neural network container that chains multiple layers together.

    Attributes
    ----------
    layers : list
        Ordered list of layer instances, each implementing:
        - forward(X: torch.Tensor) -> torch.Tensor
        - backward(dZ: torch.Tensor) -> torch.Tensor
        - update(lr: float) -> None

    device : str
        Specifies the device ('cpu' or 'cuda') on which the layers
        and tensors are (or should be) allocated.
    """

    def __init__(self, device: str = "cuda"):
        """
        Initializes an empty list of layers and sets the device.

        Parameters
        ----------
        device : str, optional
            Device to store and compute on, by default 'gpu'.
        """
        self.layers = []
        self.device = device

    def add(self, layer) -> None:
        """
        Adds a new layer to the network's sequence of layers.

        Parameters
        ----------
        layer : object
            The layer to add. This object must implement
            forward, backward, and update methods.
        """
        self.layers.append(layer)

    def forward(self, X: torch.Tensor) -> torch.Tensor:
        """
        Feeds the input X through all layers in sequence.

        Parameters
        ----------
        X : torch.Tensor
            Input data to be processed by the network.
            Its shape depends on the first layer's requirements.

        Returns
        -------
        torch.Tensor
            Final output after passing through each layer.
        """
        # Optionally ensure input is on the correct device:
        X = X.to(self.device)
        for layer in self.layers:
            X = layer.forward(X)
        return X

    def backward(self, dZ: torch.Tensor) -> torch.Tensor:
        """
        Propagates the gradient dZ backward through each layer in reverse order.

        Parameters
        ----------
        dZ : torch.Tensor
            Gradient of the loss with respect to the final output of the network.

        Returns
        -------
        torch.Tensor
            Gradient of the loss with respect to the original input of the network.
        """
        # dZ = dZ.to(self.device)  # Optionally ensure gradients on the correct device.
        for layer in reversed(self.layers):
            dZ = layer.backward(dZ)
        return dZ

    def update(self, lr: float) -> None:
        """
        Updates the trainable parameters of each layer in the network.

        Parameters
        ----------
        lr : float
            Learning rate used to scale the gradients
            when adjusting the layer parameters.
        """
        for layer in self.layers:
            layer.update(lr)

class Linear:
    """
    A fully connected (linear) layer that computes Z = XW + b.

    Attributes
    ----------
    in_features : int
        Dimensionality of each input vector (number of input features).
    out_features : int
        Dimensionality of each output vector (number of output features).
    W : torch.Tensor
        Weight matrix of shape (in_features, out_features).
    b : torch.Tensor
        Bias vector of shape (out_features,).
    X : torch.Tensor or None
        The last batch of input data used in forward, stored for use in backward.
    dW : torch.Tensor or None
        Gradient of the loss with respect to the weight matrix.
    db : torch.Tensor or None
        Gradient of the loss with respect to the bias vector.
    device : str
        Specifies the device ('cpu' or 'cuda') to store the tensors.
    """

    def __init__(self, in_features: int, out_features: int, device: str = "cuda"):
        """
        Initializes the linear layer with random weights and zero biases.

        Uses He (Kaiming) initialization to help training convergence
        when paired with ReLU-type activations. The random values are
        sampled from a normal distribution scaled by sqrt(2 / in_features).

        Parameters
        ----------
        in_features : int
            The number of input features (dimensionality of each input vector).
        out_features : int
            The number of output features (dimensionality of each output vector).
        device : str, optional
            Device to allocate tensors on, by default 'cpu'.
        """
        limit = math.sqrt(2.0 / in_features)
        # Weight matrix with shape (in_features, out_features)
        self.W = torch.randn(in_features, out_features, device=device) * limit
        # Bias vector with shape (out_features,)
        self.b = torch.zeros(out_features, device=device)

        self.in_features = in_features
        self.out_features = out_features
        self.device = device

        # Internal variables to store intermediate values/gradients
        self.X = None
        self.dW = None
        self.db = None

    def forward(self, X: torch.Tensor) -> torch.Tensor:
        """
        Computes the forward pass for a batch of inputs X.

        Z = XW + b

        Parameters
        ----------
        X : torch.Tensor
            Input tensor of shape (batch_size, in_features).

        Returns
        -------
        torch.Tensor
            Output tensor of shape (batch_size, out_features).
        """
        self.X = X
        return X @ self.W + self.b

    def backward(self, dZ: torch.Tensor) -> torch.Tensor:
        """
        Computes the backward pass, producing gradients with respect to
        weights, biases, and inputs.

        dW = X^T @ dZ
        db = sum of dZ over the batch dimension
        dX = dZ @ W^T

        Parameters
        ----------
        dZ : torch.Tensor
            Gradient of the loss with respect to the layer's output, with
            shape (batch_size, out_features).

        Returns
        -------
        torch.Tensor
            Gradient of the loss with respect to the layer's input,
            of shape (batch_size, in_features).
        """
        # Compute gradients w.r.t. weights and biases
        self.dW = self.X.t() @ dZ
        self.db = dZ.sum(dim=0)
        # Compute gradient w.r.t. inputs
        dX = dZ @ self.W.t()

        return dX

    def update(self, lr: float) -> None:
        """
        Updates the layer's parameters using the computed gradients
        and a given learning rate.

        Parameters
        ----------
        lr : float
            Learning rate used to scale the gradients.
        """
        if self.dW is not None and self.db is not None:
            self.W -= lr * self.dW
            self.b -= lr * self.db

class CrossEntropyFromLogits:
    """
    Computes the cross-entropy loss from raw (logit) inputs, and provides
    the corresponding gradient for backpropagation.

    This class expects:
    - Forward pass: input logits Z of shape (batch_size, num_classes),
      and integer labels Y of shape (batch_size,).
    - Backward pass: produces dZ of shape (batch_size, num_classes).

    Attributes
    ----------
    Y : torch.Tensor
        Stores the ground-truth labels (shape: (batch_size,)) from the last forward call.
    A : torch.Tensor
        Stores the softmax probabilities (shape: (batch_size, num_classes)) from the last forward call.
    """

    def __init__(self):
        """
        Initializes the CrossEntropyFromLogits module.
        """
        self.Y = None
        self.A = None

    def forward(self, Z: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:
        """
        Computes the cross-entropy loss given logits Z and true labels Y.

        1) softmax_Z = softmax(Z)  (stored in self.A)
        2) log_softmax_Z = log_softmax(Z)
        3) Gather the log-probabilities of the correct classes:
           log_probs = log_softmax_Z[range(batch_size), Y]
        4) Loss = -mean(log_probs)

        Parameters
        ----------
        Z : torch.Tensor
            Logits of shape (batch_size, num_classes).
        Y : torch.Tensor
            Integer class labels of shape (batch_size,).

        Returns
        -------
        torch.Tensor
            Scalar tensor representing the average cross-entropy loss.
        """
        # Store the labels for backward pass
        self.Y = Y

        # Softmax probabilities for backward (gradient) usage
        self.A = F.softmax(Z, dim=1)

        # Compute log softmax
        log_softmax_Z = F.log_softmax(Z, dim=1)

        # Gather log probabilities corresponding to correct labels
        batch_indices = torch.arange(Z.size(0), device=Z.device)
        log_probs = log_softmax_Z[batch_indices, Y]

        # Negative mean of log_probs
        loss = -log_probs.mean()

        return loss

    def backward(self, n_classes: int) -> torch.Tensor:
        """
        Computes the gradient of the cross-entropy loss with respect to the logits Z.

        dZ = A - Y_one_hot

        A is the softmax probabilities stored in self.A.
        Y_one_hot is a one-hot encoding of the ground-truth labels.

        Parameters
        ----------
        n_classes : int
            Number of classes, used to one-hot encode the labels.

        Returns
        -------
        torch.Tensor
            The gradient of the loss with respect to Z, of shape (batch_size, num_classes).
        """
        # One-hot encode the labels
        Y_one_hot = F.one_hot(self.Y, num_classes=n_classes).float()

        # Compute gradient
        dZ = self.A - Y_one_hot
        # We already took the mean in forward, so no additional division needed here.
        return dZ

class ReLU:
    """
    Rectified Linear Unit (ReLU) activation layer: ReLU(Z) = max(0, Z).

    Attributes
    ----------
    Z : torch.Tensor or None
        Stores the input tensor from the last forward pass.
        Used during backward pass to compute the correct gradient mask.
    """

    def __init__(self):
        """
        Initializes the ReLU layer.
        This layer has no trainable parameters.
        """
        self.Z = None

    def forward(self, Z: torch.Tensor) -> torch.Tensor:
        """
        Applies the ReLU function element-wise: max(0, Z).

        Parameters
        ----------
        Z : torch.Tensor
            Input tensor of any shape.

        Returns
        -------
        torch.Tensor
            Output tensor of the same shape as Z,
            with ReLU applied to each element.
        """
        self.Z = Z
        return torch.relu(Z)

    def backward(self, dA: torch.Tensor) -> torch.Tensor:
        """
        Computes the gradient of the ReLU function with respect to the input.

        dZ[i] = dA[i] if Z[i] > 0 else 0

        Parameters
        ----------
        dA : torch.Tensor
            Gradient of the loss with respect to the ReLU output,
            with the same shape as Z.

        Returns
        -------
        torch.Tensor
            Gradient of the loss with respect to Z,
            same shape as Z.
        """
        grad_mask = (self.Z > 0).float()
        dZ = grad_mask * dA
        return dZ

    def update(self, lr: float) -> None:
        """
        ReLU has no parameters to update. This method does nothing.

        Parameters
        ----------
        lr : float
            Learning rate (unused).
        """
        pass

# The following imports assume that you have:
# - Net
# - Linear
# - ReLU
# - CrossEntropyFromLogits
# already defined in the same environment/notebook.
# Otherwise, ensure they are defined or properly imported.

def load_mnist_data(batch_size: int = 64):
    """
    Loads the MNIST dataset using PyTorch's DataLoader and applies basic transformations.

    Parameters
    ----------
    batch_size : int
        The number of samples per batch.

    Returns
    -------
    tuple
        (trainloader, testloader) of DataLoader instances.
    """
    # Transform: convert to Tensor and normalize to mean=0.5, std=0.5
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    # Download and create training dataset
    trainset = torchvision.datasets.MNIST(
        root="./data",
        train=True,
        download=True,
        transform=transform
    )
    # Create DataLoader for training
    trainloader = torch.utils.data.DataLoader(
        trainset,
        batch_size=batch_size,
        shuffle=True
    )

    # Download and create testing dataset
    testset = torchvision.datasets.MNIST(
        root="./data",
        train=False,
        download=True,
        transform=transform
    )
    # Create DataLoader for testing
    testloader = torch.utils.data.DataLoader(
        testset,
        batch_size=batch_size,
        shuffle=False
    )

    return trainloader, testloader

def train_one_epoch(
    net,
    loss_fn,
    trainloader,
    lr: float,
    device: str = "cuda"
):
    """
    Trains the given network for a single epoch over the training set.

    Parameters
    ----------
    net : Net
        The neural network model (sequential container).
    loss_fn : CrossEntropyFromLogits (or any compatible loss)
        The loss function to compute cross-entropy and its gradient.
    trainloader : DataLoader
        DataLoader providing (images, labels) for the training set.
    lr : float
        Learning rate for updating the model parameters.
    device : str
        Device to move data to ('cpu' or 'cuda').

    Returns
    -------
    float
        The average training loss for this epoch.
    float
        The accuracy on the training set for this epoch.
    """
    net_loss = 0.0
    correct = 0
    total = 0

    # We will accumulate the losses over all batches to get an average.
    for images, labels in tqdm(trainloader, desc="Training", leave=False):
        images = images.view(images.size(0), -1).to(device)  # Flatten: (batch_size, 784)
        labels = labels.to(device)

        # Forward pass
        outputs = net.forward(images)
        loss = loss_fn.forward(outputs, labels)
        net_loss += loss.item() * images.size(0)

        # Backward pass
        dZ = loss_fn.backward(n_classes=10)
        net.backward(dZ)

        # Parameter update
        net.update(lr)

        # Accuracy calculation
        _, predicted = torch.max(outputs, dim=1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    avg_loss = net_loss / total
    accuracy = correct / total
    return avg_loss, accuracy

def evaluate(
    net,
    testloader,
    device: str = "cuda"
):
    """
    Evaluates the given network on the test set to compute accuracy.

    Parameters
    ----------
    net : Net
        The trained neural network model.
    testloader : DataLoader
        DataLoader providing (images, labels) for the test set.
    device : str
        Device to move data to ('cpu' or 'cuda').

    Returns
    -------
    float
        Accuracy on the test set.
    """
    correct = 0
    total = 0

    # Disable gradient computation for evaluation
    with torch.no_grad():
        for images, labels in tqdm(testloader, desc="Testing", leave=False):
            images = images.view(images.size(0), -1).to(device)
            labels = labels.to(device)

            outputs = net.forward(images)
            _, predicted = torch.max(outputs, dim=1)

            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    accuracy = correct / total
    return accuracy

def main_mnist_experiment(
    epochs: int = 2,
    lr: float = 0.001,
    batch_size: int = 64,
    device: str = "cuda"
):
    """
    Demonstrates training and testing a simple network (Linear -> ReLU -> Linear)
    on the MNIST dataset.

    Parameters
    ----------
    epochs : int
        Number of training epochs.
    lr : float
        Learning rate for parameter updates.
    batch_size : int
        Number of samples per batch in DataLoader.
    device : str
        Device to use ('cpu' or 'cuda').

    Returns
    -------
    None
    """
    # Load data
    trainloader, testloader = load_mnist_data(batch_size)

    # Create a small network
    from collections import OrderedDict
    # If needed, import your local classes:
    # from your_module import Net, Linear, ReLU, CrossEntropyFromLogits

    net = Net(device=device)
    net.add(Linear(784, 128, device=device))
    net.add(ReLU())
    net.add(Linear(128, 10, device=device))

    loss_fn = CrossEntropyFromLogits()

    train_losses = []
    train_accuracies = []

    print(f"Starting training on device={device} for {epochs} epochs.")

    for epoch in range(1, epochs + 1):
        avg_loss, train_acc = train_one_epoch(net, loss_fn, trainloader, lr, device)
        train_losses.append(avg_loss)
        train_accuracies.append(train_acc)

        print(f"Epoch [{epoch}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_acc:.4f}")

    test_acc = evaluate(net, testloader, device)
    print(f"Final Test Accuracy: {test_acc:.4f}")

    # Plot the training losses
    plt.figure(figsize=(8,5))
    plt.plot(train_losses, label="Train Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training Loss Over Epochs")
    plt.legend()
    plt.show()

    # Plot the training accuracies
    plt.figure(figsize=(8,5))
    plt.plot(train_accuracies, label="Train Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title("Training Accuracy Over Epochs")
    plt.legend()
    plt.show()

# Example usage:
#main_mnist_experiment(epochs=6, lr=0.001, batch_size=64, device="cuda")